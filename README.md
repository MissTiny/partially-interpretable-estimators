>ðŸ“‹  This README.md is mainly a description about how to train and evaluate a specific model, to see the real tuning process of the 5 fold cross-validation PIE method, please visit the readme file in **Argon** folder.

# Partially Interpretable Estimators

This repository is the official implementation of [Partially Interpretable Estimators](https://arxiv.org/abs/2030.12345). 

<!-- 
>ðŸ“‹  Optional: include a graphic explaining your approach/main result, bibtex entry, link to demos, blog posts and tutorials
-->
## Requirements

Our PIE model is constructed based on R language.

To install requirements for PIE model:

```setup
Rscript requirements.R
```

<!-- 
>ðŸ“‹  Describe how to set up the environment, e.g. pip/conda/docker commands, download datasets, etc...
-->
## Training

#### First Load the PIE algorithm functions prior training
```train
#To save all PIE algorithm functions in functions.RData file which will be called in Train.R

Rscript load_functions.R 

```
#### Train a simple model
##### Regression
To train a simple model(s) in the paper, run this command:

```train
#Train.py will generate a train.RData file of the model
Rscript Train.R dataset.RData lambda1 lambda2 stepsize iteration eta nrounds fold
```
For example, if the dataset is saved in CASP.RData file, lambda1 = 0.01, lambda2 = 1, stepsize=0.1, iteration = 500, eta = 0.05, nrounds=200 and train the model with dataset in fold 1,then the call function would be the following:

```train
Rscript Train.R CASP.RData 0.01 1 0.1 500 0.05 200 1
```
##### Classification

>ðŸ“‹  The description and function above describes how to train a simple model. However, we applied 5-fold cross-validation to elimiate bias. Please reference to the last section and Argon folder to see detailed training code and command.

## Evaluation

To evaluate my model, run:

```eval
Rscript Evaluate.R model.RData
```
Evaluate.R load the train.RData file generated by Train.R and predict with the model in Train.R. And the Evaluate.R will make prediction on both Validation Test and Real Test Dataset. So to call after Train.R

```eval
Rscript Evaluate.R train.RData
```

>ðŸ“‹  The description and function above describes how to evaluate a simple model.

## Pre-trained Models
The final result of PIE performance on one dataset is selected by tuning parameters with 5-fold cross validation method. Thus, we picked the best performance model of each fold and average the result. During the training procedure, hundreds of models are trained. It is hard to provide all models, therefore, we would provide one model of each dataset as an example.

You can download pre-trained RData files of models from the folder **Pre-trained Models**.

<!-- 
- [My awesome model](https://drive.google.com/mymodel.pth) trained on ImageNet using parameters x,y,z. 

>ðŸ“‹  Give a link to where/how the pretrained models can be downloaded and how they were trained (if applicable).  Alternatively you can have an additional column in your results table with a link to the models.
-->
## Results

#### Result Associated with Given Pre-trained Model
Our model achieves the following performance with the given example Pre-trained Models:

| Dataset            |   PIE - RPE     |   PIE - pi     |
| ------------------ |---------------- | -------------- |
| My awesome model   |     85%         |      95%       |
<!-- 
>ðŸ“‹  Include a table of results from your paper, and link back to the leaderboard for clarity and context. If your main result is a figure, include that figure and link to the command or notebook to reproduce it. 
-->
## 5-fold Cross-Validation PIE Model Training
To fully replicate the training process demonstrated in the paper, please reference to the readme file in Argon folder.

## Data Split
All the dataset reported in the paper is uploaded in the **Data** folder in RData format.

## Baseline
Please Reference to the **Baseline** folder.

## Contributing

>ðŸ“‹  Pick a licence and describe how to contribute to your code repository. 
